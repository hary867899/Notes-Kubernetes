Maintaining, Monitoring and troubleshooting kubernetes cluster 


etcd  - all the data and state of the cluster is stored in etcd... so what is the meaning of this.. it means we need to make a disaster back up and make sure of its high availability 

        where in kubernetes, etcd stores the data ?? etcd runs as pod in master-node just like every other object and stores its data in a container in that pod in the folder /var/lib/etcd 
		
		we can backup that by CronJobs ... nocen didnt show it how, but lets go forward 
		
		etcdctl is a CLI just like kubectl to interact with the etcd ... we can download it as binary directly from the github
		
		after downloading etcdctl... please create a snapshot of etcd data via below command 
		
		//  ETCDCTL_API=3 etcdctl --endpoints = endpointlink:port --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.cert --key="""/server.key snapshot save /var/lib/dat-backup.db 
		    (API Version of etcd)  (nocen will show how to find this endpoint) (certificate and key to authorise etcd via etcdctl)                                           (main command to create a snapshot)
			
	    // ETCDCTL_API=3 etcdctl --write-out=table snapshot status /var/lib/dat-backup.db 		
		   (cmd to check if the snapshot is created successfully)
		   
        --
		
        the above is for back up, if we wanna restore etcd, what needs to be done ?? but, first, what is restore ?? in the video, nocen talks about shifting etcd to other location, didnt get how to do it too, he will show it in the demo, please watch carefully and note down below 

        //     ETCDCTL_API=3 etcdctl snapshot restore /var/lib/dat-backup.db

        //     mv /var/lib/etcd /var/lib/etcd.OLD
		
		//     sudo crictl --runtime-endpoint unix:///run/containerd/containerd.sock ps 
		
		//     sudo crictl --runtime-endpoint unix:///run/containerd/containerd.sock stop $CONTAINER_ID 
		
		//     mv ./default.etcd /var/lib/etcd 
		
		
		demo02 1-etcd-container.sh file ... you have written your understanding in that file itself in vscode and pushed it to github ... please check that 
		
		
		
-------

now we gonna see about cluster upgrade 

see the demo, you can get it mostly, if you dont get it, please re-watch it again ... mostly not watching, you need to practice this, else, you might not remember it 

----------

Logging and Monitoring Kubernetes Cluster 


every kubernetes components like pods, nodes, control plane etc etc will get some logs based on thier run ...we will go each one by one.. first we will look about pods and containers 


logging in containers    -    containers will generally write out to stdout or stderr and where those standard streams goes depends container runtime and configuration (didnt even get a bit of what he is saying )(chatgpt interpretation - Containers generally write their output (like logs or error messages) to stdout and stderr. Where this output actually goes (e.g., to a log file, to the console, to a monitoring system) depends on the container runtime (like Docker) and how it is configured)
                              
							  the default logging driver when using containerd is /var/log/containers
		                      but these logs store inside of a container... when the container is lost, the logs will get removed... thats why the logs needed to store external to the containers 
		